<!DOCTYPE html><html><head><title>IRC channel logs</title><style>html {
  background: #fdfdfd;
}

h1 {
  font-weight: 300;
}

h2 {
  font-weight: 200;
}

h3 {
  padding: .5em 0;
  border-top: 3px dotted #ddd;
  margin-bottom: 0;
}

form {
  width: 400px;
  display: flex;
}

input {
  width: 100%;
  display: flex;
  border-radius: .25em 0 0 .25em;
  border: 1px solid #aaa;
  border-right: 0;
  padding: 0.5em;
}

button {
  display: flex;
  border-radius: 0 .25em .25em 0;
  background-color: #007bff;
  border: 1px solid #007bff;
  padding: .5em;
  cursor: pointer;
  color: white;
}

button:hover {
  background-color: #0069d9;
  border-color: #0062cc;
}

a {
  color: #007bff;
  text-decoration: none;
}

a:hover {
  text-decoration: underline;
}

h4 {
  margin-bottom: .5em;
}

table td {
  padding: 0.75em;
}

table tr:hover {
  background: #eee;
}

.year {
  display: table;
}

.month {
  display: table-cell;
  padding-right: 1em;
}

ul {
  margin: 0;
  padding: 0;
  list-style: none;
}

.nick {
  padding-right: 0.6rem;
  font-weight: bold;
  text-align: right;
  width: 13rem;
  display: table-cell;
}

.nick a {
  color: inherit;
  text-decoration: none;
}

.message {
  display: table-cell;
  padding-left: 0.6rem;
  border-left: 2px solid #333;
}

.notice {
  color: #859900;
  font-style: italic;
}

.line {
  line-height: 1.8rem;
  display: table;
}

#logs {
  margin-top: 1.5rem;
  padding: 1.5rem;
}
</style></head><body><h1>IRC channel logs</h1><h2>2023-04-14.log</h2><p><a href="/bootstrappable">back to list of logs</a></p><div id="logs"><div class="line" id="033431"><span class="nick" style="color:#389600"><a href="#033431" label="[03:34:31]">&lt;fossy&gt;</a></span><span class="message">doras: I am quite ok with that!</span></div><div class="line" id="113752"><span class="nick" style="color:#8dd3c7"><a href="#113752" label="[11:37:52]">&lt;river&gt;</a></span><span class="message">hello</span></div><div class="line" id="115232"><span class="nick" style="color:#2e2a4a"><a href="#115232" label="[11:52:32]">&lt;stikonas&gt;</a></span><span class="message">hi</span></div><div class="line" id="121238"><span class="nick" style="color:#8dd3c7"><a href="#121238" label="[12:12:38]">&lt;river&gt;</a></span><span class="message">i want to discuss bootstrapping relating to LLMs. but I want to be respectful of people who aren't interesting and don't care aboutLLMs. in that case they can just ignore the next messages from me i guess</span></div><div class="line" id="121913"><span class="nick" style="color:#2e2a4a"><a href="#121913" label="[12:19:13]">&lt;stikonas&gt;</a></span><span class="message">what is LLM, large language model?</span></div><div class="line" id="122313"><span class="nick" style="color:#8dd3c7"><a href="#122313" label="[12:23:13]">&lt;river&gt;</a></span><span class="message">yeah</span></div><div class="line" id="122431"><span class="nick" style="color:#8dd3c7"><a href="#122431" label="[12:24:31]">&lt;river&gt;</a></span><span class="message">I read a paper about bootstrapping a 'pretrained mode' which just generates text into a 'helpful' model which has been optimized towards responding to questions, then this was used with a &quot;constitution&quot; to perform analysis of its responses in order to further optimize it to produce 'helpful+harmless' responses</span></div><div class="line" id="122443"><span class="nick" style="color:#8dd3c7"><a href="#122443" label="[12:24:43]">&lt;river&gt;</a></span><span class="message">pretrained model*</span></div><div class="line" id="122559"><span class="nick" style="color:#8dd3c7"><a href="#122559" label="[12:25:59]">&lt;river&gt;</a></span><span class="message">I am also thinking how these LLMs are capable of doing pytorch neural network programs, which is a library that could be used to implement an LLM. they are able to produce valid pieces of code and explain the functionality and so on.</span></div><div class="line" id="122659"><span class="nick" style="color:#8dd3c7"><a href="#122659" label="[12:26:59]">&lt;river&gt;</a></span><span class="message">so there is a potential that it could process and produce modified/improved versions of its own code. that said, it seems to be 0.0001% code and 99.9999% data (many GB of data)</span></div><div class="line" id="122752"><span class="nick" style="color:#6b8072"><a href="#122752" label="[12:27:52]">&lt;doras&gt;</a></span><span class="message">fossy: great! Should I just refer to you as &quot;fossy&quot; in the presentation? :)</span></div><div class="line" id="132312"><span class="nick" style="color:#80b1d3"><a href="#132312" label="[13:23:12]">&lt;oriansj&gt;</a></span><span class="message">river: well the largest problem in LLM bootstrapping is the dataset. The code is usually a relatively simple state machine in a standard language. And from what I can tell most of the code used to train it comes from software with  free software licenses. Which mostly is an open question for the courts which have historically considered anything slightly similiar to this as a copyright violation.</span></div><div class="line" id="132700"><span class="nick" style="color:#80b1d3"><a href="#132700" label="[13:27:00]">&lt;oriansj&gt;</a></span><span class="message">The quality of the code it currently produces, is about equal to a half-drunk programmer who is so jaded, they only deliver what was requested to the letter of the specification.</span></div><div class="line" id="132835"><span class="nick" style="color:#80b1d3"><a href="#132835" label="[13:28:35]">&lt;oriansj&gt;</a></span><span class="message">and lets be honest, _A tables in the database with the corresponding update/delete triggers isn't something people tend to ask for but they should.</span></div><div class="line" id="132959"><span class="nick" style="color:#80b1d3"><a href="#132959" label="[13:29:59]">&lt;oriansj&gt;</a></span><span class="message">so from my perspective, I see it driving the cost of CRUD apps into the ground.</span></div><div class="line" id="133305"><span class="nick" style="color:#2e2a4a"><a href="#133305" label="[13:33:05]">&lt;stikonas&gt;</a></span><span class="message">and training big LLMs is not something you can do at home. You need a big data centre full of specialized GPUs and a small power plant next to it</span></div><div class="line" id="133350"><span class="nick" style="color:#2e2a4a"><a href="#133350" label="[13:33:50]">&lt;stikonas&gt;</a></span><span class="message">fossy, rickmasters: README of live-bootstrap is also a bit out of date regarding kernel bootstrap</span></div><div class="line" id="133750"><span class="nick" style="color:#6d2462"><a href="#133750" label="[13:37:50]">&lt;rickmasters&gt;</a></span><span class="message">stikonas: Do you mean the Get me started! section which advises using a kernel?</span></div><div class="line" id="133824"><span class="nick" style="color:#2e2a4a"><a href="#133824" label="[13:38:24]">&lt;stikonas&gt;</a></span><span class="message">and also in Comparison between GNU Guix and live-bootstrap</span></div><div class="line" id="133833"><span class="nick" style="color:#6d2462"><a href="#133833" label="[13:38:33]">&lt;rickmasters&gt;</a></span><span class="message">stikonas: The description of the size of seeds?</span></div><div class="line" id="133908"><span class="nick" style="color:#6d2462"><a href="#133908" label="[13:39:08]">&lt;rickmasters&gt;</a></span><span class="message">stikonas: Yeah, there is the &quot;Use of kernel&quot; line</span></div><div class="line" id="133914"><span class="nick" style="color:#234e69"><a href="#133914" label="[13:39:14]">&lt;pabs3&gt;</a></span><span class="message">river: a big problem is the training data licenses, usually it isn't even redistributable. Debian's ML policy has some stuff about that <a rel="nofollow" href="https://salsa.debian.org/deeplearning-team/ml-policy">https://salsa.debian.org/deeplearning-team/ml-policy</a> </span></div><div class="line" id="133926"><span class="nick" style="color:#80b1d3"><a href="#133926" label="[13:39:26]">&lt;oriansj&gt;</a></span><span class="message">stikonas: yeah, if it costs $10M to do a single &quot;build&quot; even basic sanity checks like reproducible builds becomes a non-starter; but perhaps as a community we could find a way to spread work out and obtain the collective benefit.</span></div><div class="line" id="133937"><span class="nick" style="color:#234e69"><a href="#133937" label="[13:39:37]">&lt;pabs3&gt;</a></span><span class="message">the other big problem is the amount of money it costs in hardware and electricity to do the training</span></div><div class="line" id="134008"><span class="nick" style="color:#234e69"><a href="#134008" label="[13:40:08]">&lt;pabs3&gt;</a></span><span class="message">then there is the CUDA problem, lots of these things rely on nvidia GPUs</span></div><div class="line" id="134035"><span class="nick" style="color:#80b1d3"><a href="#134035" label="[13:40:35]">&lt;oriansj&gt;</a></span><span class="message">??a folding@home solution potentially??</span></div><div class="line" id="134114"><span class="nick" style="color:#6d2462"><a href="#134114" label="[13:41:14]">&lt;rickmasters&gt;</a></span><span class="message">stikonas: I think I've been a bit more hesitant than fossy to change some of the claims and defaults ... because kernel bootstrapping is not done.</span></div><div class="line" id="134117"><span class="nick" style="color:#80b1d3"><a href="#134117" label="[13:41:17]">&lt;oriansj&gt;</a></span><span class="message">ironically the big LLM being produced are only 64KB</span></div><div class="line" id="134134"><span class="nick" style="color:#2e2a4a"><a href="#134134" label="[13:41:34]">&lt;stikonas&gt;</a></span><span class="message">rickmasters: yeah, we can wait a bit to update taht</span></div><div class="line" id="134318"><span class="nick" style="color:#2e2a4a"><a href="#134318" label="[13:43:18]">&lt;stikonas&gt;</a></span><span class="message">still, you have made a huge progress on kernel bootstrapping</span></div><div class="line" id="134334"><span class="nick" style="color:#2e2a4a"><a href="#134334" label="[13:43:34]">&lt;stikonas&gt;</a></span><span class="message">I was already doing some testing (to test PRs before merging) with builder-hex0 and fiwix</span></div><div class="line" id="134633"><span class="nick" style="color:#6d2462"><a href="#134633" label="[13:46:33]">&lt;rickmasters&gt;</a></span><span class="message">stikonas: I appreciate your comments and those from others. It helps keep me motivated.</span></div><div class="line" id="134943"><span class="nick" style="color:#6d2462"><a href="#134943" label="[13:49:43]">&lt;rickmasters&gt;</a></span><span class="message">I want to highlight Mikaku's contribution of Fiwix and his recent work to fix the hard drive problems.</span></div><div class="line" id="135052"><span class="nick" style="color:#6d2462"><a href="#135052" label="[13:50:52]">&lt;rickmasters&gt;</a></span><span class="message">The hard drive issue was a lot of work for both of use and was just closed: <a rel="nofollow" href="https://github.com/mikaku/Fiwix/issues/27">https://github.com/mikaku/Fiwix/issues/27</a> </span></div><div class="line" id="140012"><span class="nick" style="color:#80b1d3"><a href="#140012" label="[14:00:12]">&lt;oriansj&gt;</a></span><span class="message">of course, Mikaku clearly has spent years doing excellent work to get Fiwix to its current state.</span></div><div class="line" id="140025"><span class="nick" style="color:#8dd3c7"><a href="#140025" label="[14:00:25]">&lt;river&gt;</a></span><span class="message">oriansj: yes indeed! there is an interesting person called shawwwn who created one of the datasets that may be involved in a court case about whether the 'weights' for these model should be libre</span></div><div class="line" id="140054"><span class="nick" style="color:#8dd3c7"><a href="#140054" label="[14:00:54]">&lt;river&gt;</a></span><span class="message">that link about the debian ML policy is very interesting, thank you</span></div><div class="line" id="140137"><span class="nick" style="color:#8dd3c7"><a href="#140137" label="[14:01:37]">&lt;river&gt;</a></span><span class="message">that's a great point about cuda too. i don't know anything about the libre GPU computation stuff</span></div><div class="line" id="140142"><span class="nick" style="color:#8dd3c7"><a href="#140142" label="[14:01:42]">&lt;river&gt;</a></span><span class="message">but that is a big issue</span></div><div class="line" id="140207"><span class="nick" style="color:#80b1d3"><a href="#140207" label="[14:02:07]">&lt;oriansj&gt;</a></span><span class="message">but it is hard to overstate the importance of your work rickmasters; you have saved me more than a decade of work</span></div><div class="line" id="140322"><span class="nick" style="color:#2e2a4a"><a href="#140322" label="[14:03:22]">&lt;stikonas&gt;</a></span><span class="message">well, ROCm is libre, but AMD has a smaller market share than NVIDIA for GPU training</span></div><div class="line" id="140408"><span class="nick" style="color:#80b1d3"><a href="#140408" label="[14:04:08]">&lt;oriansj&gt;</a></span><span class="message">I like Debian's Policy (The toxicCandy bit was a nice touch)</span></div><div class="line" id="141014"><span class="nick" style="color:#6d2462"><a href="#141014" label="[14:10:14]">&lt;rickmasters&gt;</a></span><span class="message">oriansj: thank you. I appreciate that but I think you're probably underestimating what can be accomplished with sustained focus over a long period.</span></div><div class="line" id="141018"><span class="nick" style="color:#6d2462"><a href="#141018" label="[14:10:18]">&lt;rickmasters&gt;</a></span><span class="message"> <a rel="nofollow" href="https://quoteinvestigator.com/2019/01/03/estimate/">https://quoteinvestigator.com/2019/01/03/estimate/</a> </span></div><div class="line" id="142408"><span class="nick" style="color:#234e69"><a href="#142408" label="[14:24:08]">&lt;pabs3&gt;</a></span><span class="message">oriansj: I don't think the folding@home approach would work, I've read the extra network latency would blow out the training time a lot</span></div><div class="line" id="142641"><span class="nick" style="color:#6c3d55"><a href="#142641" label="[14:26:41]">&lt;avih&gt;</a></span><span class="message">re folding@home, for those who care, home electricity is not free either, and recent GPUs consume 200-400W if you let them</span></div><div class="line" id="142802"><span class="nick" style="color:#6c3d55"><a href="#142802" label="[14:28:02]">&lt;avih&gt;</a></span><span class="message">so this can add up to non negligible electricity bills...</span></div><div class="line" id="143352"><span class="nick" style="color:#d9d9d9"><a href="#143352" label="[14:33:52]">&lt;stikonas[m]&gt;</a></span><span class="message">Yes, you need very low network latency and lots of RAM</span></div><div class="line" id="144103"><span class="nick" style="color:#bc80bd"><a href="#144103" label="[14:41:03]">&lt;muurkha&gt;</a></span><span class="message">river: I think it's a really important problem, possibly the most important in the history of the universe</span></div><div class="line" id="144141"><span class="nick" style="color:#8dd3c7"><a href="#144141" label="[14:41:41]">&lt;river&gt;</a></span><span class="message">libr GPU?</span></div><div class="line" id="144239"><span class="nick" style="color:#bc80bd"><a href="#144239" label="[14:42:39]">&lt;muurkha&gt;</a></span><span class="message">oriansj: I've been impressed with the quality of the code GPT-3.5 spits out</span></div><div class="line" id="144334"><span class="nick" style="color:#389600"><a href="#144334" label="[14:43:34]">&lt;fossy&gt;</a></span><span class="message">stikonas[m], rickmasters: README is a bit outdated, yes, but i'm ok with waiting to change that until kernel bootstrapping is more done</span></div><div class="line" id="144344"><span class="nick" style="color:#389600"><a href="#144344" label="[14:43:44]">&lt;fossy&gt;</a></span><span class="message">the primary reason i wanted it default is to avoid regressions</span></div><div class="line" id="144354"><span class="nick" style="color:#389600"><a href="#144354" label="[14:43:54]">&lt;fossy&gt;</a></span><span class="message">(after knowing that it wouldn't be fully complete on first PR)</span></div><div class="line" id="144410"><span class="nick" style="color:#bc80bd"><a href="#144410" label="[14:44:10]">&lt;muurkha&gt;</a></span><span class="message">river: bootstrapping AI</span></div><div class="line" id="144422"><span class="nick" style="color:#8dd3c7"><a href="#144422" label="[14:44:22]">&lt;river&gt;</a></span><span class="message">ahh</span></div><div class="line" id="144503"><span class="nick" style="color:#389600"><a href="#144503" label="[14:45:03]">&lt;fossy&gt;</a></span><span class="message">river: first we need open LLMs lol...</span></div><div class="line" id="144605"><span class="nick" style="color:#389600"><a href="#144605" label="[14:46:05]">&lt;fossy&gt;</a></span><span class="message">i think it's going to take at *least* 5 years until today's LLMs are reproducible in &lt;$50k (even if they are open)</span></div><div class="line" id="144611"><span class="nick" style="color:#389600"><a href="#144611" label="[14:46:11]">&lt;fossy&gt;</a></span><span class="message">the training is just so prohibitive</span></div><div class="line" id="144705"><span class="nick" style="color:#389600"><a href="#144705" label="[14:47:05]">&lt;fossy&gt;</a></span><span class="message">last year I heard that that revision of Google's LAMDA was already trained on &gt;300TB (iirc) of data</span></div><div class="line" id="144731"><span class="nick" style="color:#389600"><a href="#144731" label="[14:47:31]">&lt;fossy&gt;</a></span><span class="message">i imagine that today's are in the PBs of data</span></div><div class="line" id="145025"><span class="nick" style="color:#bc80bd"><a href="#145025" label="[14:50:25]">&lt;muurkha&gt;</a></span><span class="message">oriansj: like, yesterday, <a rel="nofollow" href="http://sprunge.us/xFnyrV">http://sprunge.us/xFnyrV</a>  — but maybe it's just repeating some code from its training set nearly verbatim</span></div><div class="line" id="145148"><span class="nick" style="color:#bc80bd"><a href="#145148" label="[14:51:48]">&lt;muurkha&gt;</a></span><span class="message">there's a bug in that the triangles it draws are always invisible because they are inside the rectangle of the same color</span></div><div class="line" id="145325"><span class="nick" style="color:#bc80bd"><a href="#145325" label="[14:53:25]">&lt;muurkha&gt;</a></span><span class="message">it took under a minute to produce that</span></div><div class="line" id="151157"><span class="nick" style="color:#bc80bd"><a href="#151157" label="[15:11:57]">&lt;muurkha&gt;</a></span><span class="message">fossy: I think the future is a lot less predictable than you think it is</span></div><div class="line" id="151339"><span class="nick" style="color:#389600"><a href="#151339" label="[15:13:39]">&lt;fossy&gt;</a></span><span class="message">how do you mean</span></div><div class="line" id="151520"><span class="nick" style="color:#bc80bd"><a href="#151520" label="[15:15:20]">&lt;muurkha&gt;</a></span><span class="message">it's easy to imagine more breakthroughs that improve trainability by orders of magnitude, like ReLU did</span></div><div class="line" id="151535"><span class="nick" style="color:#bc80bd"><a href="#151535" label="[15:15:35]">&lt;muurkha&gt;</a></span><span class="message">but there are also second-order and third-order effects</span></div><div class="line" id="151650"><span class="nick" style="color:#bc80bd"><a href="#151650" label="[15:16:50]">&lt;muurkha&gt;</a></span><span class="message">also, algorithmic improvements tend to have bigger effects on larger data: an algorithmic improvement that only saves you 50% at N=1000 might save you 99% at N = 1e9</span></div><div class="line" id="151828"><span class="nick" style="color:#389600"><a href="#151828" label="[15:18:28]">&lt;fossy&gt;</a></span><span class="message">oh, for sure, i did explicitly mean today's LLMs in terms of the way they are trained and their dataset. but even befoer you even get to training - you need to be able to have the raw compute + bandwith to obtain the training corpus, let alone process it. algorithmic improvements will do very little to help that, its just good old storage+network engineering that improves that</span></div><div class="line" id="151928"><span class="nick" style="color:#bc80bd"><a href="#151928" label="[15:19:28]">&lt;muurkha&gt;</a></span><span class="message">oh, it's very likely that today's LLMs aren't reproducible in that sense at all</span></div><div class="line" id="152000"><span class="nick" style="color:#bc80bd"><a href="#152000" label="[15:20:00]">&lt;muurkha&gt;</a></span><span class="message">not just because they were tweaking the code during the training process but also because it's probably actually nondeterministic</span></div><div class="line" id="152038"><span class="nick" style="color:#bc80bd"><a href="#152038" label="[15:20:38]">&lt;muurkha&gt;</a></span><span class="message">it's evident that current training methods are very inefficient in their use of trainign data</span></div><div class="line" id="152041"><span class="nick" style="color:#bc80bd"><a href="#152041" label="[15:20:41]">&lt;muurkha&gt;</a></span><span class="message">*training</span></div><div class="line" id="152042"><span class="nick" style="color:#389600"><a href="#152042" label="[15:20:42]">&lt;fossy&gt;</a></span><span class="message">right, which is why i think AI bootstrapping, if it ever does occur, will not occur through any historical path</span></div><div class="line" id="152059"><span class="nick" style="color:#bc80bd"><a href="#152059" label="[15:20:59]">&lt;muurkha&gt;</a></span><span class="message">I agree</span></div><div class="line" id="152107"><span class="nick" style="color:#389600"><a href="#152107" label="[15:21:07]">&lt;fossy&gt;</a></span><span class="message">it wont be feasible to do it in the same way we have done other software (effectively a bit of time travel)</span></div><div class="line" id="152130"><span class="nick" style="color:#bc80bd"><a href="#152130" label="[15:21:30]">&lt;muurkha&gt;</a></span><span class="message">second- and third-order effects: what happens when we can use AI to explore the design space of chip fabrication?</span></div><div class="line" id="152143"><span class="nick" style="color:#389600"><a href="#152143" label="[15:21:43]">&lt;fossy&gt;</a></span><span class="message">yeah, that shall be very interesting</span></div><div class="line" id="152150"><span class="nick" style="color:#bc80bd"><a href="#152150" label="[15:21:50]">&lt;muurkha&gt;</a></span><span class="message">or asteroid mining?</span></div><div class="line" id="160819"><span class="nick" style="color:#3c5b35"><a href="#160819" label="[16:08:19]">&lt;Mikaku&gt;</a></span><span class="message">I appreciate your kind words, rickmasters has done and continues doing a really good job and I'm amazed at how quick he hacked the Fiwix kernel</span></div><div class="line" id="162112"><span class="nick" style="color:#8dd3c7"><a href="#162112" label="[16:21:12]">&lt;river&gt;</a></span><span class="message">unrelated, i just saw this on HN <a rel="nofollow" href="https://intuitiveexplanations.com/tech/kalyn">https://intuitiveexplanations.com/tech/kalyn</a> </span></div><div class="line" id="165903"><span class="nick" style="color:#2e2a4a"><a href="#165903" label="[16:59:03]">&lt;stikonas&gt;</a></span><span class="message">river: at least for now this is not bootsrappable</span></div><div class="line" id="165928"><span class="nick" style="color:#2e2a4a"><a href="#165928" label="[16:59:28]">&lt;stikonas&gt;</a></span><span class="message">it needs haskell...</span></div><div class="line" id="204349"><span class="nick" style="color:#af8d2f"><a href="#204349" label="[20:43:49]">&lt;gforce_d11977&gt;</a></span><span class="message">rickmasters: oh my god, what have you done. back from vacation and the builder.hex0 works. As delivered in the prophecy. Where is the Party/barbeque starting?</span></div><div class="line" id="204629"><span class="nick" style="color:#6d2462"><a href="#204629" label="[20:46:29]">&lt;rickmasters&gt;</a></span><span class="message">gforce_d11977: lol. I still need to get Fiwix to launch Linux so we have a full bootstrap but yeah a lot of it is working and integrated into live-bootstrap.</span></div><div class="line" id="204832"><span class="nick" style="color:#6d2462"><a href="#204832" label="[20:48:32]">&lt;rickmasters&gt;</a></span><span class="message">gforce_d11977: I'm in NYC right now. Sadly, good bbq is hard to find.</span></div><div class="line" id="211821"><span class="nick" style="color:#af8d2f"><a href="#211821" label="[21:18:21]">&lt;gforce_d11977&gt;</a></span><span class="message">rickmasters: i'am from the central-BBQ state inside germany where roasting a sausage is a religion (so i'am used to it). A good BBQ does not need much: It consists of a small set of people having spare time, a campfire and some stories to tell. It's essential at least once a week 8-)</span></div><div class="line" id="212243"><span class="nick" style="color:#af8d2f"><a href="#212243" label="[21:22:43]">&lt;gforce_d11977&gt;</a></span><span class="message">Is'nt there the &quot;central park&quot;, where you can just start a small BBQ? e.g. <a rel="nofollow" href="https://prod-metro-markets.imgix.net/item_image/79bf9851-4e59-42b8-8eae-8c91ba17263c?auto=format">https://prod-metro-markets.imgix.net/item_image/79bf9851-4e59-42b8-8eae-8c91ba17263c?auto=format</a>,compress </span></div><div class="line" id="212334"><span class="nick" style="color:#6d2462"><a href="#212334" label="[21:23:34]">&lt;rickmasters&gt;</a></span><span class="message">gforce_d11977: That sounds fun.</span></div><div class="line" id="213425"><span class="nick" style="color:#6d2462"><a href="#213425" label="[21:34:25]">&lt;rickmasters&gt;</a></span><span class="message">gforce_d11977: I think you can BBQ in Central Park but I haven't. I'll have to look into that.</span></div><div class="line" id="214239"><span class="nick" style="color:#bc80bd"><a href="#214239" label="[21:42:39]">&lt;muurkha&gt;</a></span><span class="message">NYC?</span></div><div class="line" id="214256"><span class="nick" style="color:#bc80bd"><a href="#214256" label="[21:42:56]">&lt;muurkha&gt;</a></span><span class="message">interesting!</span></div><div class="line" id="215622"><span class="nick" style="color:#389600"><a href="#215622" label="[21:56:22]">&lt;j-k-web&gt;</a></span><span class="message">trying to build mes using kaem.run &amp; my mescc-tools (with M2-planet). It goes pretty well, I get to the M1 part on line 126 but it has a tantrum `/build/mes.M1:19 :Received invalid other; lea_eax,[ebp+DWORD]`.  INSTALL doc says it's known to work with mescc-tools 1.4.0 so maybe I should just be using that instead of</span></div><div class="line" id="215623"><span class="nick" style="color:#389600"><a href="#215623" label="[21:56:23]">&lt;j-k-web&gt;</a></span><span class="message">`e8ffea3b2ab1cad652d37c0beafe93c8e75b6ddf` (I'm using release 0.24.2 of mes)</span></div><div class="line" id="220123"><span class="nick" style="color:#2e2a4a"><a href="#220123" label="[22:01:23]">&lt;stikonas&gt;</a></span><span class="message">j-k-web: mes 0.24.2 needs a patch to work with latest stage0-posix</span></div><div class="line" id="220302"><span class="nick" style="color:#2e2a4a"><a href="#220302" label="[22:03:02]">&lt;stikonas&gt;</a></span><span class="message"> <a rel="nofollow" href="https://git.savannah.gnu.org/cgit/mes.git/commit/?h=wip&amp;id=8b18e71c73e9367e586c378a1056837de7c23729">https://git.savannah.gnu.org/cgit/mes.git/commit/?h=wip&amp;id=8b18e71c73e9367e586c378a1056837de7c23729</a> </span></div><div class="line" id="220312"><span class="nick" style="color:#2e2a4a"><a href="#220312" label="[22:03:12]">&lt;stikonas&gt;</a></span><span class="message">or use this workaround <a rel="nofollow" href="https://github.com/fosslinux/live-bootstrap/blob/master/sysa/mes-0.24.2/mes-0.24.2.kaem#L50">https://github.com/fosslinux/live-bootstrap/blob/master/sysa/mes-0.24.2/mes-0.24.2.kaem#L50</a> </span></div><div class="line" id="220513"><span class="nick" style="color:#389600"><a href="#220513" label="[22:05:13]">&lt;j-k-web&gt;</a></span><span class="message">perfect. I'll give that a go now. tyvm</span></div><div class="line" id="221150"><span class="nick" style="color:#6d2462"><a href="#221150" label="[22:11:50]">&lt;rickmasters&gt;</a></span><span class="message">muurkha: My home base is Seattle</span></div><div class="line" id="234409"><span class="nick" style="color:#80b1d3"><a href="#234409" label="[23:44:09]">&lt;oriansj&gt;</a></span><span class="message">rickmasters: as the father of a 3 year old who disassembles doors, sustained focus over anything is a rare thing for me these days.</span></div><div class="line" id="234639"><span class="nick" style="color:#80b1d3"><a href="#234639" label="[23:46:39]">&lt;oriansj&gt;</a></span><span class="message">river: making your own self-hosting language is pretty trivial (especially if you allow inline assembly)</span></div><br /></div></body></html>